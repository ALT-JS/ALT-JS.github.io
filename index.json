
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I’m a University student of SIST in ShanghaiTech University. My research interests include Artificial Intelligence, Deep Learning, Computer Vision and LLMs. I have independently finished two small projects for CASTIC, Tencent Rhinobird High School Scientific Training Program and Intel ISEF from high school.\n","date":1700265600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1700265600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m a University student of SIST in ShanghaiTech University. My research interests include Artificial Intelligence, Deep Learning, Computer Vision and LLMs. I have independently finished two small projects for CASTIC, Tencent Rhinobird High School Scientific Training Program and Intel ISEF from high school.","tags":null,"title":"Jiashen Du","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Hugo Blox Builder’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://alt-js.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Hugo Blox Builder's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":null,"content":"Overview You will train your own flow matching model on MNIST.\nPart 1: Training a Single-Step Denoising UNet Unconditioned UNet architecture Visualization of the noising process Training loss curve Sample results on the test set after the first and the 5-th epoch Sample results on the test set with out-of-distribution noise levels after the model is trained. Sample results on the test set with pure noise Average image of the training set The average MNIST image is blurry and lacks clear digits, showing general intensity distributions. The denoised results, however, retain distinct shapes, indicating that it is doing denoising.\nPart 2: Training a Flow Matching Model Training loss curve plot for the time-conditioned UNet over the whole training process Sampling results for the time-conditioned UNet for 5 and 10 epochs Training loss curve plot for the class-conditioned UNet over the whole training process Sampling results for the class-conditioned UNet for 5 and 10 epochs ","date":1741478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741478400,"objectID":"93339e616d1e686cc6422476ea78c8c0","permalink":"https://alt-js.github.io/post/280pj2/","publishdate":"2025-03-09T00:00:00Z","relpermalink":"/post/280pj2/","section":"post","summary":"Overview You will train your own flow matching model on MNIST.\nPart 1: Training a Single-Step Denoising UNet Unconditioned UNet architecture Visualization of the noising process Training loss curve Sample results on the test set after the first and the 5-th epoch Sample results on the test set with out-of-distribution noise levels after the model is trained.","tags":null,"title":"COMPSCI 280 Project2: Flow Matching","type":"post"},{"authors":null,"categories":null,"content":" Part 0: Project overview In this project, I implemented some fundamental functions and features of a physically-based renderer using path tracing algorithm. First, I implemented ray generation and the intersection between ray and objects/scene. Next, I implemented the BVH splitting and intersection detection. Then, I implemented direct illumination(zero/one bounce lights) and global illumination(multi-bounce lights w/ w/o russian roullete) to actually render the whole scene with path tracing. Finally, I implemented adaptive sampling to reduce the noise of monte carlo path tracing.\nPart 1: Ray Generation and Scene Intersection Ray generation walkthrough \u0026amp; primitive intersection pipeline I first calculate the bottom left and the top right corner of the sensor/image space coordinates, which helps me to determine the coordinates in the camera space with left multiplcation of the c2w matrix. Then with the origin pos and the previously calculated coord as direction vector(since the origin is [0,0,0] and it’s numerically the same for the coords and the vector), we can generate the correct ray.\nPrimitive is the bridge between geometry processing and the shading subsystem. It contains all the things including bbox, intersect, has_intersection and bsdf. For intersections, we use has_intersection to determine whether it’s intersected or not and use intersect to actually change the intersection distance, the normal vector, and the bsdf.\nTriangle intersection algorithm walkthrough For the intersect and has_intersection, I used the Moller-Trumbore algorithm to compute them. We compute two edges of the triangle. Compute the determinant det to check if the ray is nearly parallel. Compute u and v(barycentric coordinates) to ensure the intersection lies within the triangle. Compute t, the intersection distance along the ray. And finally check if t is within the ray’s valid range (min_t to max_t). The function intersect basically determine whether has_intersection is true or not and change the primitives and the properties mentioned above(intersection distance, normal vector, bsdf).\nSome results CB spheres cow Part 2: Bounding Volume Hierarchy BVH construction algorithm walkthrough First, compute the bounding box (BBox) of all primitives in the given range [start, end). Then, I choose the best axis to split: compute the bounding box centroid for each primitive. Select the axis with the largest extent (X, Y, or Z) and split at the centroid median to achieve balanced partitions. The primitives are sorted first and partitioned into left and right subsets. Finally, recursively call function and construct BVH for left and right subsets and return the newly created BVHNode.\nSome results CB Lucy Max Planck More on BVH acceleration First, here’s more result on the BVH rendering(left) and the comparison between the non-BVH. You can see that there’s basically no difference between them.\nPeter w/ BVH Peter w/o BVH But the rendering time, as shown in the picture below, have significant difference. One is 0.0653 second, and the other takes 166.5520 seconds to finish. Nearly 300x faster.\nPart 3: Direct Illumination Direct Lighting functions walkthrough Uniform Hemisphere Sampling In the loop of num_sample samples, we sample from hemisphereSampler, then we create a new ray with in point hit_p and the epsilon constant for avoiding numerical presision issues and direction sampled earlier. If the ray intersects we calculate the L_out of the ray. Finally we divide the sum of all the things above with pdf and the num_samples.\nImportance Sampling Lights FOr importance sampling, we sample all the lights directly After we calculate the hit point hit_p, we directly sample a light ray from it. If we cast a ray in this direction and there is no other object between the hit point and the light source, then we know that this light source does cast light onto the hit point. After the judge, we still do the same thing as above(divide the sum of all the things above with pdf and the num_samples).\nSome results Hemisphere uniform sampling Direct importance sampling Hemisphere uniform sampling Direct importance sampling Direct comparison Up 1 Down 16 Up 4 Down 64 Conclusion Uniform hemisphere sampling distributes samples evenly over the hemisphere, leading to significant variance in Monte Carlo integration when evaluating lighting contributions, especially in scenes with strong directional lighting. This results in more noise and slower convergence. In contrast, importance sampling strategically places more samples in directions where the light source contributes most to the radiance, reducing variance and improving efficiency. This method converges faster, producing smoother and more accurate results with fewer samples.\nPart 4: Global Illumination Indirect lighting function walkthough We get the one bounce radiance first, then, we sample a new f using the outgoing direction of the last ray. We create new ray and increase its depth by 1. When the depth …","date":1741046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741046400,"objectID":"17b2ae3a1e133096d9f00282fc867632","permalink":"https://alt-js.github.io/post/184pj3/","publishdate":"2025-03-04T00:00:00Z","relpermalink":"/post/184pj3/","section":"post","summary":"Part 0: Project overview In this project, I implemented some fundamental functions and features of a physically-based renderer using path tracing algorithm. First, I implemented ray generation and the intersection between ray and objects/scene.","tags":null,"title":"COMPSCI 184 Project3: PathTracer","type":"post"},{"authors":null,"categories":null,"content":"Part 0: Project overview This homework focuses on implementing fundamental operations related to Bezier curves, Bezier patches, mesh manipulation, and Loop subdivision. In this project, we started out from the basic Bezier curve and de Casteljau algorithm, and extend it to 2D surfaces. We also made a fully functional mesh “editor” that does edge flipping, edge splitting and mesh upsampling. The most challenging parts were ensuring correct pointer assignments in the edge splitting and properly handling newEdge in Loop subdivision.\nSection 1: Bezier Curves and Surfaces Part 1: Bezier Curves with 1D de Casteljau Subdivision Briefly explain de Casteljau’s algorithm and how you implemented it in order to evaluate Bezier curves. De Casteljau’s algorithm is used to determine the point on the Bezier curve of a certain number of points. For $n$ points, we iteratively use linear interpolation to determine $n-1$ points, until we only have one point, which is $p_{\\frac{n(n-1)}{2}}$. This particular point will be on the Bezier curve of $p_{0}$ and $p_{n-1}$ from the original $n$ points.\nI wrote a seperate lerp function and iterate it through all the points. The lerp function is defined as: $$\\text{lerp}(p_i, p_{i+1}, t) = (1 - t) p_i + t p_{i + 1}$$\rThe new points generated is the one-step result of all the original points.\nThe Bezier curve with 6 control points The six pictures below shows the 5 steps of evaluation of the original 6 control points and the final bezier of the points.\nIn this picture I changed the position of the points and the $t$ value. A slightly different Bezier curve Part 2: Bezier Surfaces with Separable 1D de Casteljau Briefly explain how de Casteljau algorithm extends to Bezier surfaces and how you implemented it in order to evaluate Bezier surfaces. The de Casteljau’s algorithm naturally extends to Bezier surfaces by applying the same interpolation process in two directions $u$ and $v$. For each row of control points $P(i,j)$, apply the de Casteljau algorithm recursively to compute an intermediate set of points at parameter $u$, reducing the row into a single point. Once you have the intermediate points from the previous step, apply de Casteljau along the $v$-direction to interpolate these points and obtain the final surface point $S(u,v)$.\nI modified the lerp function to make it accept Vector3D inputs and outputs, and the evaluate process is just call evaluate1D on controlPoints, and return with the results of the previous loop being run in the evaluate1D again but with a different interpolation parameter. The evaluate1D function also loops through points with evaluateStep but only returns the 0-th dimension of the result.\nThe teapot result the screenshot of bez/teapot.bez evaluated by my implementation Part 3: Area-Weighted Vertex Normals Briefly explain how you implemented the area-weighted vertex normals. Started with one halfedge, we iterate through every halfedge. For every halfedge, we extract the previous, current, next vertex position, and calculate the cross product of vectors defined by current and next vertex and current and previous vertex. We add up all the cross products and restore it to unit vector as the output.\nThe teapot result default flat shading Phong shading Part 4: Edge Flip Briefly explain how you implemented the edge flip operation. I first determine every possible element of a unit pair of triangles, then, I changed the relations of every possible related halfedge using setNeighbors function, and assign the faces and vertices with the correct halfedge in the end. Here’s a picture that contains all the notations I’m using in my code. Flip edge draft The teapot result The original teapot The teapot woth some flipped edges The freakin’debug journey From the draft, you probably noticed that I initially wrote the vertex $c$ and $d$ in the wrong place. Because I sticked to my draft so closely, I kept checking the errors in my code, not the draft itself:(.\nPart 5: Edge Split Briefly explain how you implemented the edge split operation I first did all the things similar to the filpEdge function(determine possible elements), then I created new edge, face and halfedges. For the new edgeHere’s a picture that contains all the notations I’m using in my code. Split edge draft Some teapot result The original teapot The teapot with some split edges The teapot with some splits and filpped edges Part 6: Loop Subdivision for Mesh Upsampling Briefly explain how you implemented the loop subdivision I first compute new positions for all the vertices in the input mesh, using the weighted average formula given in the question. Mark each vertex as being a vertex of the original mesh, and compute the updated vertex positions associated with edges new positions. Then loop through the mesh to split edges and setting new halfedges generated, as well as filp any new edge that connects an old and new vertex to make the mesh more “organized”. Finally we copy the new vertex positions into …","date":1739836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1739836800,"objectID":"e9d23a9ec0d689ae9458043415953aee","permalink":"https://alt-js.github.io/post/184pj2/","publishdate":"2025-02-18T00:00:00Z","relpermalink":"/post/184pj2/","section":"post","summary":"Part 0: Project overview This homework focuses on implementing fundamental operations related to Bezier curves, Bezier patches, mesh manipulation, and Loop subdivision. In this project, we started out from the basic Bezier curve and de Casteljau algorithm, and extend it to 2D surfaces.","tags":null,"title":"COMPSCI 184 Project2: Geometric Modeling","type":"post"},{"authors":null,"categories":null,"content":"\r","date":1738627200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738627200,"objectID":"7aab0d825215c4f0ffb319328388f621","permalink":"https://alt-js.github.io/post/184pj1/","publishdate":"2025-02-04T00:00:00Z","relpermalink":"/post/184pj1/","section":"post","summary":"\r","tags":null,"title":"COMPSCI 184 Project1: The Simple Rasterizer","type":"post"},{"authors":["Jiashen Du"],"categories":null,"content":"CS 184/284A Spring 2025 Contents Project 1: The Simple Rasterizer\nProject 2: Geometric Modeling\nProject 3: PathTracer\n","date":1738368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738368000,"objectID":"ee3be828929d331d788f774f8676c639","permalink":"https://alt-js.github.io/post/compsci184/","publishdate":"2025-02-01T00:00:00Z","relpermalink":"/post/compsci184/","section":"post","summary":" Summary page for CS 184/284A Spring 2025 Course Projects","tags":["cg","berkeley"],"title":"Foundations of Computer Graphics Projects","type":"post"},{"authors":null,"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"6d96f58e01743cc735e5475ad5beac28","permalink":"https://alt-js.github.io/project/layerbylayer/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/project/layerbylayer/","section":"project","summary":"This is a fundamental track project for COMPSCI194-196 LLM Agents and LLM Agents hackathon. We focused on exploring robust and generalizable internal representations of lightweight LLMs and investigating the progression of learned features with linear probes and sparse autoencoders in OthelloGPT. Our experiments reveal that SAEs provide a more robust and disentangled decoding of the features the model is learning, particularly for compositional attributes.","tags":null,"title":"How GPT learn layer by layer","type":"project"},{"authors":null,"categories":null,"content":"","date":1731196800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731196800,"objectID":"edfd6cd55c767cb23660e756df984dd5","permalink":"https://alt-js.github.io/project/zen/","publishdate":"2024-11-10T00:00:00Z","relpermalink":"/project/zen/","section":"project","summary":"This is a Meta Quest track project for the Stanford XR Hackathon. We focused on recovering human psychological dysfunctions, aiming to provide a comprehensive treatment protocol by designing multiple simple interactive meditation games utilizing the power of Meta Quest3. We build interactive environments from scratch in Unity; users can choose different environments, background music, and meditation guidance in Zen.","tags":null,"title":"Zen","type":"project"},{"authors":["Chengfeng Zhao","Juze Zhang","Jiashen Du","Ziwei Shan","Junye Wang","Jingyi Yu","Jingya Wang","Lan Xu"],"categories":null,"content":"\r","date":1700265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700265600,"objectID":"db766a39b922ffd6abc3784535eeb951","permalink":"https://alt-js.github.io/publication/conference-paper/imhoi/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/imhoi/","section":"publication","summary":"In this paper, we present I'm-HOI, a monocular scheme to faithfully capture the 3D motions of both the human and object in a novel setting, using a minimal amount of RGB camera and object-mounted Inertial Measurement Unit (IMU).","tags":[],"title":"I’M HOI: Inertia-aware Monocular Capture of 3D Human-Object Interactions","type":"publication"},{"authors":null,"categories":null,"content":"","date":1603756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603756800,"objectID":"0b9687d5837bd2714f6b1f0da637348d","permalink":"https://alt-js.github.io/project/mobilenetv3/","publishdate":"2020-10-27T00:00:00Z","relpermalink":"/project/mobilenetv3/","section":"project","summary":"My small project that took part in Tencent Rhinobird High School Scientific Training Program in high school, uses light-weight neural network backbone, MobileNetV3 to detect fire, targeting for applications in portable devices and edge computing.","tags":null,"title":"A light-weight self-accomodate fire detection system","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Hugo Blox Builder Hugo Blox Builder | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://alt-js.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Hugo Blox Builder's Slides feature.","tags":[],"title":"Slides","type":"slides"}]